{
  "hash": "d2b3d0c9548c0383974d045d2b0015e2",
  "result": {
    "markdown": "---\ntitle: \"Topic 2: Decision Trees\"\nauthor: \"Chiraag Potharaju\"\ndate: \"2023-09-26\"\ncategories: [news, code, analysis]\nimage: \"Decision-Trees-2.png\"\n---\n\nThis post gives detailed descriptions and analysis about Decision Trees\n\n<br>\n\n**Introduction to Decision Trees**\n\nDecision trees are very powerful and a versatile machine learning technique used for both classification and regression tasks. Throughout this blog post, we will explore decision trees, discussing their fundamental concepts and how they can be applied various real-world problems. Using Python, Scikit-learn, Tensorflow, graphs, executable code blocks, and other visualization tools, we will show the different features as well as advantages of decision trees.\n\n<br>\n\n**Importance of Decision Trees**\n\nDecision trees are hierarchical structures with the purpose of mimicking human decision-making processes. They consists of nodes representing decision and branches that symbolize different outcomes, and at the bottom, we are left with leafs, which represent final decisions. These trees can be used or a wide range of tasks such as diagnosis medical conditions or predicting customer behavior. Some advantages include:\n\n-   Easy to explain with a clear visualization of the process.\n\n-   Can handle both numerical and categorical data.\n\n-   Very little data preprocessing, meaning it can handle missing data or outliers.\n\n-   No assumptions are made about the shape or distribution of data.\n\n<br>\n\n**Step 0:**\n\nThis step is to ensure that required libraries are installed on the machine before proceeding.\n\n```         \n---   pip install numpy pandas matplotlib scikit-learn ---\n```\n\nThis step installs the required libraries to run the code below. Ensure python is installed on the machine already and the terminal has admin access when running this command.\n\n<br>\n\n**Step 1:**\n\nWhen using Python, we have to import some libraries that will be utilized throughout the process.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import plot_tree\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\nSome of the imports include numpy and pandas for data manipulation, sklearn modules from training and evaluation, and DecisionTreeClassifier for building the model.\n\n<br>\n\n**Step 2:**\n\nImport the data set\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.datasets import load_iris  \n\niris_data = load_iris() \nX = iris_data.data \ny = iris_data.target\n```\n:::\n\n\nThis code imports the iris data set and loads the data and target values into variables.\n\n<br>\n\n**Step 3:**\n\nWe can peek the data by plotting a scatter-plot matrix.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\niris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\niris_df['target'] = iris_data.target\n\npd.plotting.scatter_matrix(iris_df.drop('target', axis=1), c=iris_df['target'], figsize=(10, 8))\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=798 height=645}\n:::\n:::\n\n\nBy executing the commands above, we are given a scatter-plot matrix that gives a visualization of the relationships in the data.\n\n<br>\n\n**Step 4:**\n\nNext, we will split the data into training and testing sets\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\nWe used a test_size of 0.2 meaning that 20% of the data will be allocated for testing and 80% will be used for training. The rest of the variables are different data and target points being inserted.\n\n<br>\n\n**Step 5:**\n\nAfter dividing the data, we will train a Decision Tree classifier.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nmodel = DecisionTreeClassifier() \nmodel.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nThis code fits the model on the training data.\n\n<br>\n\n**Step 6:**\n\nEvaluate the test set\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\npredictions = model.predict(X_test) \naccuracy = accuracy_score(y_test, predictions)  \n\nprint(\"Accuracy:\", accuracy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 1.0\n```\n:::\n:::\n\n\nThis code helps to evaluate the data and print out the accuracy values.\n\n<br>\n\n**Step 7:**\n\nThe following code is to visualize the decision tree containing the data.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 8))\nplot_tree(model, filled=True, feature_names=iris_data.feature_names, class_names=iris_data.target_names)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=912 height=611}\n:::\n:::\n\n\nThe trees structure and nodes are displayed above, making it more visible as to the computations that were done and how every decision was made.\n\n<br>\n\n**Step 8:**\n\nIf we want to make predictions on new data, we need to simulate new points, add the data, and tell the scalar to make the appropriate predictions.\n\nThis is example of a data set.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nnew_data = np.array([[5.1, 3.8, 1.5, 0.3]]) \n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnew_data = scaler.transform(new_data) \n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\nnew_predictions = model.predict(new_data)\n\nprint(\"Predicted class for custom data:\", iris_data.target_names[new_predictions[0]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredicted class for custom data: setosa\n```\n:::\n:::\n\n\nAs we can see, when using those specific values, the model predicts that the class of the entered data is virginica.\n\nBelow, we will use a different data set and see the results.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nnew_data = np.array([[0.1, 0.8, 0.5, 0.3]]) \n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nnew_data = scaler.transform(new_data) \n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\nnew_predictions = model.predict(new_data)\n\nprint(\"Predicted class for custom data:\", iris_data.target_names[new_predictions[0]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPredicted class for custom data: setosa\n```\n:::\n:::\n\n\nAs we can see, when using those specific values, the model predicts that the class of the entered data is versicolor. This is a different prediction from the custom values we used originally, showing how the model is parsing through the different options of the decision tree.\n\n<br>\n\n**Conclusion:**\n\nAs we can see, decision trees are a very effective and efficient tool. Once the model is trained on the data, it can then make several decisions and predictions for various classification and regression purposes. In the future, decision trees will continue to get stronger and more accurate, allowing data analysts to make more decisions.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}